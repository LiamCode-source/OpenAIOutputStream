// This file was generated by Mendix Studio Pro.
//
// WARNING: Only the following code will be retained when actions are regenerated:
// - the import list
// - the code between BEGIN USER CODE and END USER CODE
// - the code between BEGIN EXTRA CODE and END EXTRA CODE
// Other code you write will be lost the next time you deploy the project.
import "mx-global";
import { Big } from "big.js";

// BEGIN EXTRA CODE
// END EXTRA CODE

/**
 * Takes a text input and streams out the output
 * @param {MxObject} outputStream - Object that stores output text
 * @param {string} inputMessage - Message sent to model
 * @param {string} modelName - e.g. gpt-4.1-mini
 * @param {string} apiKey
 * @param {string} endpoint - e.g. https://api.openai.com/v1/chat/completions
 * @param {boolean} showProgressBar - Show progress bar before stream starts
 * @param {"OpenAIOutputStream.ENUM_OpenAI_Type.AzureOpenAI"|"OpenAIOutputStream.ENUM_OpenAI_Type.OpenAI"} apiType
 * @returns {Promise.<boolean>}
 */
export async function JS_OpenAI_OutputStream(outputStream, inputMessage, modelName, apiKey, endpoint, showProgressBar, apiType) {
	// BEGIN USER CODE
let idProg;

let headers = {}

if (apiType === "AzureOpenAI") {
    headers = {
        "Content-Type": "application/json",
        "api-key": apiKey,
        "Accept": "text/event-stream"
    };
}

else if (apiType === "OpenAI") {
    headers = {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${apiKey}`,
        "Accept": "text/event-stream"
    };
}



if (showProgressBar) {
    idProg = mx.ui.showProgress("Thinking...", false);
}

// Prepare the streaming POST request
const response = await fetch(endpoint, {

method: "POST",
headers: headers,
body:JSON.stringify({
      "model": modelName,
      "messages": [
        { "role": "user", "content": inputMessage }
      ],
      "stream": true
    })
})



    // Error check before streaming
    if (!response.ok || !response.body) {
        const errorText = await response.text().catch(() => "");
        const message = `Request failed (${response.status} ${response.statusText})\n${errorText}`;
        console.error(message);
        // Stop execution
        return false;
        }

    // Handle streamed chunks
    const reader = response.body.getReader();
    const decoder = new TextDecoder("utf-8");
    let done = false;

    if (showProgressBar) {
        mx.ui.hideProgress(Number(idProg));
    }

    // Initialize Mendix object field if needed
    outputStream.set("OutputText", "");

    while (!done) {
        const { value, done: streamDone } = await reader.read();
        done = streamDone;

        if (value) {
            const chunk = decoder.decode(value, { stream: true });

            // Each chunk may contain one or more 'data: {...}' events
            const lines = chunk.split("\n").filter(line => line.trim().startsWith("data:"));
            for (const line of lines) {
                const json = line.replace(/^data:\s*/, "");
                if (json === "[DONE]") continue;

                try {
                    const parsed = JSON.parse(json);
                    const delta = parsed.choices?.[0]?.delta?.content;
                    if (delta) {
                        // Append streamed text into Mendix object
                        outputStream.set("OutputText", outputStream.get("OutputText") + delta);
                    }
                } catch (e) {
                    console.error("Failed to parse chunk:", e);
                }
            }
		mx.data.commit({
			mxobj: outputStream,
			callback: function() {
				console.log("Final streaming text committed.");
			}
});

        }
    }

    console.log("Streaming complete.");
    return true
	// END USER CODE
}
